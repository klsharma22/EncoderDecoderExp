{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a mind map before getting into action\n",
    "\n",
    "So after coming across from the mistakes before this notebook, let's plan what all things we need to do so that we perform the crucial steps needed for the NMT to make with all the proper components and the preprocessed data.\n",
    "\n",
    "**Data Preprocessing Actions**:\n",
    "1. Shift the target texts.\n",
    "2. Pad the text with proper annotations.\n",
    "\n",
    "**Components of the model**:\n",
    "1. Create *text vectors* of both source and target language separately using TensorFlow `TextVectorization` layer.\n",
    "2. Create *embedding layers* of both source and target language separately using TensorFlow `Embedding` layer.\n",
    "3. Create a class known *Encoder* which inherits the properties of TensorFlow class `Layer`. In the sub-class method of creating a layer, we are going to develop the encoder architecture of the NMT. (The architecture will be discussed while we are developing the layer.)\n",
    "4. Create a class known as *Decoder* which inherits the properties of TensorFlow class `Layer`. In this sub-class method of creating a layer, we are going to develop the decoder architecture of the NMT. (The architecture will be discussed while we are developing the layer.)\n",
    "5. After creating all the components, we are going to create a class called *EncoderDecoder* which will inherit from TensorFlow class `Model`. In this class we will assemble all of the layers that we have prepared in the above steps and then create a custom call function which will allow us to train the decoder layer as we expect it to do.\n",
    "6. Create an instance of the *EncoderDecoder* class with all the parameters passed in its constructor and compile the model with `tf.keras.losses.SparseCategoricalCrossentropy()` as loss function and `tf.keras.optimizers.RMSprop()` as the optimizer.\n",
    "7. We will then create the *train_dataset* and *valid_dataset* using TensorFlow `tf.data` API for better performance of the model training.\n",
    "8. We will fit the model with the training data with 5 epochs and *callbacks* such as `tf.keras.callbacks.ModelCheckPoint`, `tf.keras.callbacks.EarlyStopping`, `tf.keras.callbacks.ReduceLROnPlateau` and the validation dataset.\n",
    "9. After training the model we will evaluate the model using different metrics system and predict with an unseen data and observe the quality of the prediction."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e240db960ed8729"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing all the necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9430d4d813aceb5"
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tarfile\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:51.989694Z",
     "start_time": "2024-04-07T09:09:47.450394Z"
    }
   },
   "id": "bfdf0bb37b8c825a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start the project\n",
    "\n",
    "As all machine learning project has two phases, this is project is no exception for it. We will first work on the *Data Preprocessing* and then *Model Development*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64a05be9d25b00fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f9de603448c9b31"
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating a constant which contains the starting path of the project so that\n",
    "START_PATH = str(os.getcwd()) + '/'\n",
    "COMP_DATA_PATH = os.path.join(START_PATH, 'wiki-titles.tgz')\n",
    "DATA_URL = 'https://www.statmt.org/wmt14/wiki-titles.tgz'\n",
    "DATA_DIR = os.path.join(START_PATH, 'wiki/hi-en/wiki-titles.hi-en')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:51.993161Z",
     "start_time": "2024-04-07T09:09:51.990978Z"
    }
   },
   "id": "e37d49d18a6631f1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eaef38bbde5b36b"
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(COMP_DATA_PATH):\n",
    "    print(f'Downloading data from {DATA_URL}')\n",
    "    !wget https://www.statmt.org/wmt14/wiki-titles.tgz\n",
    "else:\n",
    "    print(\"Data already downloaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:51.996569Z",
     "start_time": "2024-04-07T09:09:51.993983Z"
    }
   },
   "id": "43050224ec71df74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(COMP_DATA_PATH):\n",
    "    print(\"File does not exist\")\n",
    "else:\n",
    "    print(\"The file exists\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:51.999870Z",
     "start_time": "2024-04-07T09:09:51.997730Z"
    }
   },
   "id": "5f1139795316c182",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "with tarfile.open(COMP_DATA_PATH, 'r') as tar_ref:\n",
    "    tar_ref.extractall()\n",
    "    print(\"File extracted\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:52.116023Z",
     "start_time": "2024-04-07T09:09:52.000489Z"
    }
   },
   "id": "a0c519a809d4a9ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracting data from file "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5f8236ca4c75de5"
  },
  {
   "cell_type": "code",
   "source": [
    "# Extracting the lines from the file of the dataset\n",
    "with open(DATA_DIR, 'r') as f:\n",
    "    lines = f.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:52.124095Z",
     "start_time": "2024-04-07T09:09:52.116924Z"
    }
   },
   "id": "8706972bebef0f20",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Splitting the data into two list of source language and target language\n",
    "src_senteces = [line.split('|||')[1][1:-1] for line in lines]\n",
    "trg_sentences = [line.split('|||')[0][:-1] for line in lines]\n",
    "src_senteces[:10], trg_sentences[:10], len(src_senteces), len(trg_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:52.141307Z",
     "start_time": "2024-04-07T09:09:52.124842Z"
    }
   },
   "id": "1878ae100a6b426f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['January 0',\n",
       "  'March 0',\n",
       "  '1000',\n",
       "  '1001',\n",
       "  '1002',\n",
       "  '1003',\n",
       "  '1004',\n",
       "  '1005',\n",
       "  '1006',\n",
       "  '1007'],\n",
       " ['० जनवरी',\n",
       "  '० मार्च',\n",
       "  '१०००',\n",
       "  '१००१',\n",
       "  '१००२',\n",
       "  '१००३',\n",
       "  '१००४',\n",
       "  '१००५',\n",
       "  '१००६',\n",
       "  '१००७'],\n",
       " 32863,\n",
       " 32863)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c90fb2692dc8df"
  },
  {
   "cell_type": "code",
   "source": [
    "def visualise_random_sentences(src_sent, trg_sent):    \n",
    "    random_idx = random.randint(0, len(src_sent))\n",
    "    \n",
    "    print(f\"Source sentence: {src_sent[random_idx]}\")\n",
    "    print(f\"Target sentence: {trg_sent[random_idx]}\")\n",
    "    \n",
    "visualise_random_sentences(src_sent= src_senteces,\n",
    "                    trg_sent= trg_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:52.145659Z",
     "start_time": "2024-04-07T09:09:52.142929Z"
    }
   },
   "id": "36e32e67bba57146",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence: National Highway 22 \n",
      "Target sentence: राष्ट्रीय राजमार्ग २२\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shift the target data with one token"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd558fc2e24c14d4"
  },
  {
   "cell_type": "code",
   "source": [
    "trg_sentences_preprocessed = ['<SOS> ' + sentence + ' <EOS>' for sentence in trg_sentences]\n",
    "visualise_random_sentences(src_sent= src_senteces,\n",
    "                           trg_sent= trg_sentences_preprocessed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:52.150711Z",
     "start_time": "2024-04-07T09:09:52.146325Z"
    }
   },
   "id": "9c752ba428dc9646",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence: Good Will Hunting\n",
      "Target sentence: <SOS> गुड विल हंटिंग <EOS>\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the max length of the text for each language lists\n",
    "src_word_per_sentence = [len(line.split()) for line in src_senteces]\n",
    "trg_word_per_sentence = [len(line.split()) for line in trg_sentences_preprocessed]\n",
    "\n",
    "max_src_len = max(src_word_per_sentence)\n",
    "max_trg_len = max(trg_word_per_sentence)\n",
    "\n",
    "print(f\"Max source sentence length: {max_src_len}\")\n",
    "print(f\"Max target sentence length: {max_trg_len}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T09:09:52.164905Z",
     "start_time": "2024-04-07T09:09:52.152619Z"
    }
   },
   "id": "86d7ec2f1690e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source sentence length: 13\n",
      "Max target sentence length: 17\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T11:20:59.035321Z",
     "start_time": "2024-04-07T11:20:59.004794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Storing vocab\n",
    "src_vocab, trg_vocab = set(), set()\n",
    "for sentence in src_senteces:\n",
    "    for word in sentence.split():\n",
    "        src_vocab.add(word)\n",
    "        \n",
    "for sentence in trg_sentences:\n",
    "    for word in sentence.split():\n",
    "        trg_vocab.add(word)\n",
    "        \n",
    "len(src_vocab), len(trg_vocab)"
   ],
   "id": "66b0de55d8d0b6ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28851, 29073)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T11:23:59.165587Z",
     "start_time": "2024-04-07T11:23:59.153929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splitting the data into train and test\n",
    "src_train, src_test, trg_train, trg_test = train_test_split(src_senteces, trg_sentences_preprocessed, test_size=0.2, random_state= 42)\n",
    "\n",
    "len(src_train), len(trg_train), len(src_test), len(trg_test)"
   ],
   "id": "6333b37f1a6ec396",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26290, 26290, 6573, 6573)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "source": [
    ">**Note**: Padding of the data will be done after vectorising the text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e5640df1a236aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model development\n",
    "\n",
    "We have completed the data preprocessing of the data and are ready to develop the model. Let's discuss the steps we are going to take for it:\n",
    "1. Create individual components\n",
    "2. Assemble the model\n",
    "3. Create Data Pipeline\n",
    "4. Fit the model\n",
    "5. Evaluate the model\n",
    "6. Predict using the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e38c8a72bd5d08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Components\n",
    "\n",
    "Before starting with the model, first we need to create some building blocks for the Encoder Decoder archtiecture of NMT. The components that we are going to make here are:\n",
    "1. Encode layer:\n",
    "        * *Inheritance*: `tf.keras.layers.Layer`\n",
    "        * *Constructor Input*: \n",
    "        * *Call function Input*: src_sentences\n",
    "        * *Return*: Encoder output, RNN layer states\n",
    "2. Decoder layer:\n",
    "        * *Inheritance*: `tf.keras.layers.Layer`\n",
    "        * *Constructor Input*: \n",
    "        * *Call function Input*: trg_sentences_preprocessed, context, encoder_states\n",
    "        * *Return*: RNN output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4feaa32e6d6dc13b"
  },
  {
   "cell_type": "code",
   "source": [
    "# Creation of Encoder layer class\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    This class creates a custom encoder layer based on the Google's research paper of NMT.\n",
    "    For more reference please view https://arxiv.org/pdf/1609.08144.pdf%20(7\n",
    "    \n",
    "    This class is an inheritied class from `tf.keras.layers.Layer`. In this class, we will create the constructor\n",
    "    of the encoder layer and then define the call function so that we can set the working of the encoder layer using \n",
    "    Functional API.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, units: int, dropout_rate: float, num_layers: int, **kwargs):\n",
    "        '''\n",
    "        Constructs the encoder\n",
    "        \n",
    "        Parameters:\n",
    "            units: Nuumber of neurons required per LSTM layer\n",
    "            dropout_rate: to set the dropout rate\n",
    "            num_layers: to set the number of encoding layer\n",
    "        Returns:\n",
    "            An instance of Encoder class which works as the encoder described in the research paper\n",
    "        '''\n",
    "        \n",
    "        # calling the super method to initialise\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # initialising all the object variables\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # initialise the layers\n",
    "        self.bi_lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units= self.units // 2,\n",
    "                                                                                return_sequences=True,\n",
    "                                                                                dropout=self.dropout_rate),\n",
    "                                                           name= 'encoder_bi_lstm_layer')\n",
    "        \n",
    "        self.lstm_recurrent_layers = []\n",
    "        for i in range(self.num_layers - 1):\n",
    "            self.lstm_recurrent_layers.append(tf.keras.layers.LSTM(units= self.units,\n",
    "                                                         return_sequences=True,\n",
    "                                                         return_state=True,\n",
    "                                                         dropout=self.dropout_rate,\n",
    "                                                         name= f'encoder_lstm_recurrent_layer_{i + 1}'))\n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.bi_lstm_layer(inputs)\n",
    "        x, h, c = self.lstm_recurrent_layers[0](x)\n",
    "        x = self.add_layer([x, h, c])\n",
    "        for layer in self.lstm_recurrent_layers:\n",
    "            x, h, c = layer(x)\n",
    "            x = self.add_layer([x, h, c])\n",
    "        \n",
    "        return x, h, c\n",
    "    \n",
    "encoder_layer = Encoder(units= 512, \n",
    "                        dropout_rate= 0.5,\n",
    "                        name= 'encoder_layer',\n",
    "                        num_layers= 8)\n",
    "encoder_layer.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:11.760850Z",
     "start_time": "2024-04-07T16:54:11.737159Z"
    }
   },
   "id": "cbf34e085cf398ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'encoder_layer',\n",
       " 'units': 512,\n",
       " 'dropout_rate': 0.5,\n",
       " 'num_layers': 8,\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "source": [
    "# Checking the functionality of the layer using dummy values\n",
    "encoder_output, encoder_hidden, encoder_carry = encoder_layer(tf.random.uniform(shape=(10, 17, 128)))\n",
    "encoder_output.shape, encoder_hidden.shape, encoder_carry.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:18.518486Z",
     "start_time": "2024-04-07T16:54:17.535154Z"
    }
   },
   "id": "74724396ff40e996",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 17, 512]), TensorShape([10, 512]), TensorShape([10, 512]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Decoder class\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    This class creates is for an instance of Decoder layer. This inherits the properties of `tf.keras.layers.Layer`.\n",
    "    We are going to create the constructor and the call function which will contain the Functional API structure\n",
    "    of computing the values which is the input.\n",
    "    \n",
    "    This layer is refered from the above mentioned paper.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, units: int, num_layers: int, dropout_rate: float, **kwargs):\n",
    "        '''\n",
    "        Constructor of the decoder class which helps initialize the variables and create the layer\n",
    "        Parameters:\n",
    "            units: number of neurons in the LSTM layer\n",
    "            num_layers: number of layers expected in the decoder layer\n",
    "            embedding_size: to set the input value of the layer\n",
    "            dropout_rate: to set the dropout rate of the LSTM layer\n",
    "            \n",
    "        Returns:\n",
    "            An instance of the decoder class which will act as a layer\n",
    "        '''\n",
    "        \n",
    "        # calling the super function\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # initialising all the variables\n",
    "        self.units = units\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.encoder_layer = encoder_layer\n",
    "        \n",
    "        # initialising the layers\n",
    "        # self.lstm_cell = tf.keras.layers.LSTMCell(units= self.units,\n",
    "        #                                           name= 'decoder_lstm_cell')\n",
    "        self.lstm_layers = []\n",
    "        for i in range(self.num_layers):\n",
    "            self.lstm_layers.append(tf.keras.layers.LSTM(units= self.units,\n",
    "                                                          return_sequences=True,\n",
    "                                                         return_state=True,\n",
    "                                                         dropout=self.dropout_rate,\n",
    "                                                          name= f'decoder_lstm_layer_{i}'))\n",
    "            self.add_layer = tf.keras.layers.Add()\n",
    "            self.attention_layer = tf.keras.layers.Attention()\n",
    "    \n",
    "    def call(self, inputs, encoder_output):\n",
    "        x, _, _ = self.lstm_layers[0](inputs)\n",
    "        x = self.attention_layer([x, encoder_output])\n",
    "        # print(context.shape)\n",
    "        x, h, c = self.lstm_layers[1](x)\n",
    "        x = self.add_layer([x, h, c])\n",
    "        for layer in self.lstm_layers[2:]:\n",
    "            x, h, c = layer(x)\n",
    "            x = self.add_layer([x, h, c])\n",
    "        \n",
    "        \n",
    "        return  x, h, c\n",
    "        \n",
    "decoder_layer = Decoder(units= 512,\n",
    "                        num_layers= 8,\n",
    "                        dropout_rate= 0.5)\n",
    "decoder_layer.get_config()     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:20.228614Z",
     "start_time": "2024-04-07T16:54:20.204063Z"
    }
   },
   "id": "1d1819ef306c596e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'decoder_18',\n",
       " 'units': 512,\n",
       " 'num_layers': 8,\n",
       " 'dropout_rate': 0.5,\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "source": [
    "# Testing decoder layer\n",
    "decoder_output, decoder_hidden, decoder_carry = decoder_layer(tf.random.uniform(shape= (10, 17, 128)), encoder_output= encoder_output)\n",
    "print(decoder_output.shape, decoder_hidden.shape, decoder_carry.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:23.348103Z",
     "start_time": "2024-04-07T16:54:22.415989Z"
    }
   },
   "id": "1b93f07282625874",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 17, 512) (10, 512) (10, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klsharma22/PycharmProjects/EncoderDecoderExp/venv/lib/python3.10/site-packages/keras/src/layers/layer.py:357: UserWarning: `build()` was called on layer 'decoder_18', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assemble Components into Model\n",
    "\n",
    "We have created the components that we require for the Encoder Decoder NMT. The components are as follows:\n",
    "1. Encoder layer\n",
    "2. Decoder layer with attention layer\n",
    "\n",
    "Now in the below cell we are going to assemble all the parts in this order:\n",
    "1. Source input layer\n",
    "2. Source Text Vectorizer layer\n",
    "3. Source Embedding layer\n",
    "4. Encoder layer\n",
    "5. Target input layer\n",
    "6. Target Text Vectorizer layer\n",
    "7. Target Embedding layer\n",
    "8. Decoder layer\n",
    "9. Final dense softmax layer with target vocab size as output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7919e25a54c6e23a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:26.182240Z",
     "start_time": "2024-04-07T16:54:26.087624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating Text Vectorizer layer\n",
    "src_text_vectorizer_layer = tf.keras.layers.TextVectorization(max_tokens= len(src_vocab),\n",
    "                                                            pad_to_max_tokens= True,\n",
    "                                                            output_sequence_length= max(max_src_len, max_trg_len))\n",
    "trg_text_vectorizer_layer = tf.keras.layers.TextVectorization(max_tokens= len(trg_vocab),\n",
    "                                                            pad_to_max_tokens= True,\n",
    "                                                            output_sequence_length= max(max_trg_len, max_src_len))\n",
    "\n",
    "# Adapting the vectorizer\n",
    "src_text_vectorizer_layer.adapt(src_train)\n",
    "trg_text_vectorizer_layer.adapt(trg_train)"
   ],
   "id": "23b7a43ba71f210f",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:28.025543Z",
     "start_time": "2024-04-07T16:54:28.013551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the text vectorizer\n",
    "random_idx = random.randint(0, len(src_train))\n",
    "\n",
    "print(f\"Src Text: {src_train[random_idx]}\")\n",
    "print(f\"Src Vector: {src_text_vectorizer_layer(src_train[random_idx])}\")\n",
    "print(f\"Trg Text: {trg_train[random_idx]}\")\n",
    "print(f\"Trg Vector: {trg_text_vectorizer_layer(trg_train[random_idx])}\")"
   ],
   "id": "6d6314aca531c60a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src Text: Tehran Province\n",
      "Src Vector: [3440   19    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "Trg Text: <SOS> तेहरान प्रांत <EOS>\n",
      "Trg Vector: [   2 4899   57    3    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:54:31.053902Z",
     "start_time": "2024-04-07T16:54:30.998172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderDecoder(tf.keras.Model):\n",
    "    '''\n",
    "    This class assembles the above layers created and final gives us an instance of the model where the encoder decoder architecture functions.\n",
    "    '''\n",
    "    def __init__(self, encoder_units: int, \n",
    "                 encoder_dropout_rate: float, \n",
    "                 encoder_num_layers: int, \n",
    "                 decoder_units: int,\n",
    "                 decoder_dropout_rate: float,\n",
    "                 decoder_num_layers: int,\n",
    "                 embedding_size: int, **kwargs):\n",
    "        '''\n",
    "        Constructor of the encoder decoder architecture model\n",
    "        \n",
    "        Parameters:\n",
    "            encoder_units: units of encoder LSTM layer\n",
    "            encoder_droput_rate: dropout rate of the encoder LSTM layer\n",
    "            encoder_num_layers: number of encoder LSTM layers\n",
    "            decoder_units: units of decoder LSTM layer\n",
    "            decoder_dropout_rate: dropout rate of the decoder LSTM layer\n",
    "            decoder_num_layers: number of decoder LSTM layers\n",
    "            embedding_size: to set the embedding size of the embedding layer of both source and target input\n",
    "        Return:\n",
    "            An instance of EncoderDecoder class which inherits the properties of `tf.keras.layers.Layer`. This instnace will be used to fit and train the model.\n",
    "        '''\n",
    "        # Calling the super class to initiate the variables\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Initialising the object variables\n",
    "        self.encoder_units = encoder_units\n",
    "        self.encoder_dropout_rate = encoder_dropout_rate,\n",
    "        self.encoder_num_layers = encoder_num_layers\n",
    "        self.decoder_units = decoder_units\n",
    "        self.decoder_dropout_rate = decoder_dropout_rate\n",
    "        self.decoder_num_layers = decoder_num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Creating all the necessary instances\n",
    "        self.encoder_layer = Encoder(units= self.encoder_units,\n",
    "                                     dropout_rate= self.encoder_dropout_rate,\n",
    "                                     num_layers= self.encoder_num_layers,\n",
    "                                     name= 'encoder_layer')\n",
    "        self.decoder_layer = Decoder(units= self.decoder_units,\n",
    "                                      num_layers= self.decoder_num_layers,\n",
    "                                      dropout_rate= self.decoder_dropout_rate,\n",
    "                                      name= 'decoder_layer')\n",
    "        self.encoder_embedding_layer = tf.keras.layers.Embedding(input_dim= len(src_vocab),\n",
    "                                                                 output_dim= self.embedding_size, \n",
    "                                                                 name= 'encoder_embedding_layer')\n",
    "        self.decoder_embedding_layer = tf.keras.layers.Embedding(input_dim= len(trg_vocab),\n",
    "                                                                 output_dim= self.embedding_size, \n",
    "                                                                 name= 'decoder_ embedding_layer')\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "model = EncoderDecoder(encoder_units= 512,\n",
    "                       encoder_dropout_rate= 0.5,\n",
    "                       encoder_num_layers= 8,\n",
    "                       decoder_units= 512,\n",
    "                       decoder_dropout_rate= 0.5,\n",
    "                       decoder_num_layers= 8,\n",
    "                       embedding_size= 128,\n",
    "                       name= 'encoder_decoder')\n"
   ],
   "id": "92f9a076438ae8af",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[94], line 57\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     55\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 57\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mEncoderDecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder_units\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mencoder_dropout_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mencoder_num_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mdecoder_units\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mdecoder_dropout_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mdecoder_num_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m                       \u001B[49m\u001B[43membedding_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mencoder_decoder\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[94], line 39\u001B[0m, in \u001B[0;36mEncoderDecoder.__init__\u001B[0;34m(self, encoder_units, encoder_dropout_rate, encoder_num_layers, decoder_units, decoder_dropout_rate, decoder_num_layers, embedding_size, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_size \u001B[38;5;241m=\u001B[39m embedding_size\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Creating all the necessary instances\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_layer \u001B[38;5;241m=\u001B[39m \u001B[43mEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43munits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder_units\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mdropout_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder_dropout_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder_num_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mencoder_layer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_layer \u001B[38;5;241m=\u001B[39m Decoder(units\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_units,\n\u001B[1;32m     44\u001B[0m                               num_layers\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_num_layers,\n\u001B[1;32m     45\u001B[0m                               dropout_rate\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_dropout_rate,\n\u001B[1;32m     46\u001B[0m                               name\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdecoder_layer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_embedding_layer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(input_dim\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(src_vocab),\n\u001B[1;32m     48\u001B[0m                                                          output_dim\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_size, \n\u001B[1;32m     49\u001B[0m                                                          name\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoder_embedding_layer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[88], line 33\u001B[0m, in \u001B[0;36mEncoder.__init__\u001B[0;34m(self, units, dropout_rate, num_layers, **kwargs)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers \u001B[38;5;241m=\u001B[39m num_layers\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# initialise the layers\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbi_lstm_layer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mBidirectional(\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[43munits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munits\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mreturn_sequences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_rate\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     36\u001B[0m                                                    name\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoder_bi_lstm_layer\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm_recurrent_layers \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/EncoderDecoderExp/venv/lib/python3.10/site-packages/keras/src/layers/rnn/lstm.py:459\u001B[0m, in \u001B[0;36mLSTM.__init__\u001B[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    433\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    434\u001B[0m     units,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    458\u001B[0m ):\n\u001B[0;32m--> 459\u001B[0m     cell \u001B[38;5;241m=\u001B[39m \u001B[43mLSTMCell\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43munits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrecurrent_activation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrecurrent_activation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    465\u001B[0m \u001B[43m        \u001B[49m\u001B[43munit_forget_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munit_forget_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    466\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrecurrent_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrecurrent_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_initializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrecurrent_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrecurrent_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_regularizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrecurrent_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrecurrent_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_constraint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbias_constraint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrecurrent_dropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrecurrent_dropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrainable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlstm_cell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimplementation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimplementation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    483\u001B[0m         cell,\n\u001B[1;32m    484\u001B[0m         return_sequences\u001B[38;5;241m=\u001B[39mreturn_sequences,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[1;32m    492\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_spec \u001B[38;5;241m=\u001B[39m InputSpec(ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/EncoderDecoderExp/venv/lib/python3.10/site-packages/keras/src/layers/rnn/lstm.py:133\u001B[0m, in \u001B[0;36mLSTMCell.__init__\u001B[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, **kwargs)\u001B[0m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurrent_constraint \u001B[38;5;241m=\u001B[39m constraints\u001B[38;5;241m.\u001B[39mget(recurrent_constraint)\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias_constraint \u001B[38;5;241m=\u001B[39m constraints\u001B[38;5;241m.\u001B[39mget(bias_constraint)\n\u001B[0;32m--> 133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurrent_dropout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0.0\u001B[39m, recurrent_dropout))\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseed \u001B[38;5;241m=\u001B[39m seed\n",
      "\u001B[0;31mTypeError\u001B[0m: '>' not supported between instances of 'tuple' and 'float'"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Data Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2266b292296397b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0179c38bd36ef20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate model Performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9f9847f3fcba8cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making Predictions using the best model trained"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7b2bd1cb7fbf1dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
